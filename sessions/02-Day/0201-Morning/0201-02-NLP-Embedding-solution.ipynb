{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0201-02 - NLP Embedding - Solution Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Written by Alexandre Gazagnes\n",
    "* Last update: 2024-02-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the party started ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data  : \n",
    "\n",
    "**You can find the dataset [here](https://gist.githubusercontent.com/AlexandreGazagnes/cabe445634a092d308d17a883a305a75/raw/9f785f0f02739ac6352e1d583323771d55270221/nlp.csv).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These commands will display the system information:\n",
    "\n",
    "Uncomment theses lines if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install various Librairies : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt >> pip.log\n",
    "# !pip freeze >> pip.freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, warnings\n",
    "import pickle\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.impute import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.pipeline import *\n",
    "from sklearn.feature_extraction import *\n",
    "from sklearn.dummy import *\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "# from lightgbm import *\n",
    "# from xgboost import *\n",
    "\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.neighbors import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# import wordcloud\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "import string\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim\n",
    "\n",
    "import gensim\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.downloader import load\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.parsing.preprocessing import preprocess_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "# warnings.filterwarnings(action=\"once\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISPLAY = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thrid Parties Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need some Third parties : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some string assets : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "punctuation = set(string.punctuation)\n",
    "word_dict = words.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to download spacy : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm\n",
    "!python -m spacy download en_core_web_md\n",
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2vect : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2c = load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to load spacy model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "url of the dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://gist.githubusercontent.com/AlexandreGazagnes/cabe445634a092d308d17a883a305a75/raw/d2014e8a34bba3c1be3ec8936bb338fb42888f24/nlp.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(url)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep a copy of the df : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## King - Men + Woman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize 'King' : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "king = nlp(\"king\")\n",
    "king"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(king)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the vector : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "king_v = king.vector\n",
    "king_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(king.vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for Man : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "man = nlp(\"man\")\n",
    "man_v = man.vector\n",
    "man_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(man_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for wooman : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woman = nlp(\"woman\")\n",
    "woman_v = woman.vector\n",
    "woman_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fancy calculation ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = king_v - man_v + woman_v\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape new vector : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.reshape(1, -1)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Similarity : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = nlp.vocab.vectors.most_similar(res, n=20)\n",
    "vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v1 is : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = vectors[0][0][0]\n",
    "v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vect is :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = nlp.vocab[v1]\n",
    "vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text is :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = vectors[0][0][1]\n",
    "vect = nlp.vocab[v2]\n",
    "vect.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3 = vectors[0][0][2]\n",
    "vect = nlp.vocab[v3]\n",
    "vect.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoooo .... not so good ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do the same with a \"huge\" model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download en_core_web_md\n",
    "# !python -m spacy download en_core_web_lg\n",
    "!python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good ? ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just re-run previous cells with this code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are your conclusions ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try another last trick : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"He is one of the most famous kings:  Richard III was the last king of England to die in battle\"\n",
    "doc = nlp(doc)\n",
    "king = doc[-7]\n",
    "king"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "king_v = king.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"Fifteen months after the death of King George VI, his daughter Elizabeth is crowned Queen of England\"\n",
    "doc = nlp(doc)\n",
    "queen = doc[-3]\n",
    "queen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queen_v = queen.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"a female, it's a woman, or a lady, a human of female sex.\"\n",
    "doc = nlp(doc)\n",
    "woman = doc[6]\n",
    "woman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woman_v = woman.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "king_v = king.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"a boy, a guy, or a man, it's a human being of male sex.\"\n",
    "doc = nlp(doc)\n",
    "man = doc[8]\n",
    "man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "man_v = man.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = nlp.vocab.vectors.most_similar(queen_v.reshape(1, -1), n=20)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t_id in out[0][0]:\n",
    "    print(nlp.vocab[t_id].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Doc2Vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same with Pretrained Doct2Vect : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = w2c.most_similar(positive=[\"woman\", \"king\"], negative=[\"man\"], topn=10)\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create y vector : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T12:18:27.463765Z",
     "start_time": "2023-02-22T12:18:27.277572Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df.cat_1\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create X : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv():\n",
    "    return StratifiedShuffleSplit(n_splits=5, test_size=0.25)\n",
    "\n",
    "\n",
    "cv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our documents : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T12:24:50.897459Z",
     "start_time": "2023-02-22T12:24:50.890472Z"
    }
   },
   "outputs": [],
   "source": [
    "documents = df.description\n",
    "documents[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init spacy : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess (clean) the corpus : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T12:25:42.803825Z",
     "start_time": "2023-02-22T12:25:22.555754Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_docs = [\n",
    "    [\n",
    "        token.lemma_\n",
    "        for token in nlp(doc.lower())\n",
    "        if not token.is_stop and not token.is_punct\n",
    "    ]\n",
    "    for doc in documents\n",
    "]\n",
    "tokenized_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key concept here is a tagged document => Token + id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_docs = [\n",
    "    TaggedDocument(words=doc, tags=[i]) for i, doc in enumerate(tokenized_docs)\n",
    "]\n",
    "tagged_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Doc2Vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sm : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T12:26:12.958857Z",
     "start_time": "2023-02-22T12:26:04.105331Z"
    }
   },
   "outputs": [],
   "source": [
    "# 5s\n",
    "model_sm = Doc2Vec(\n",
    "    tagged_docs,\n",
    "    vector_size=50, # size of output vect\n",
    "    window=2,  # nb words before and after a target word \n",
    "    min_count=1, # minimum frequency count of words. ,\n",
    "    workers=4, # number of cpu\n",
    "    epochs=100, # number of iterations (passes over the entire dataset)\n",
    ")\n",
    "\n",
    "model_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "md : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10s\n",
    "model_md = Doc2Vec(\n",
    "    tagged_docs, vector_size=100, window=4, min_count=1, workers=4, epochs=200,\n",
    ")\n",
    "model_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lg : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30s\n",
    "model_lg = Doc2Vec(\n",
    "    tagged_docs, vector_size=500, window=10, min_count=1, workers=4, epochs=500,)\n",
    "model_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xl : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 15m => 1h\n",
    "# model_xl = Doc2Vec(\n",
    "#     tagged_docs,\n",
    "#     vector_size=1_000,\n",
    "#     window=10,\n",
    "#     min_count=1,\n",
    "#     workers=4,\n",
    "#     epochs=2_000,\n",
    "# )\n",
    "# model_xl\n",
    "\n",
    "\n",
    "# 1m => 15m\n",
    "model_xl = Doc2Vec(\n",
    "    tagged_docs,\n",
    "    vector_size=1_000,\n",
    "    window=10,\n",
    "    min_count=1,\n",
    "    workers=4,\n",
    "    epochs=1_000,\n",
    ")\n",
    "model_xl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the vectors : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T12:29:24.481191Z",
     "start_time": "2023-02-22T12:29:13.060124Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2=> 5 mins with xl\n",
    "doc_vectors = [model_xl.infer_vector(doc) for doc in tokenized_docs]\n",
    "print(doc_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Type : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T12:29:24.491186Z",
     "start_time": "2023-02-22T12:29:24.486319Z"
    }
   },
   "outputs": [],
   "source": [
    "type(doc_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length ? : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T12:29:33.460373Z",
     "start_time": "2023-02-22T12:29:33.456054Z"
    }
   },
   "outputs": [],
   "source": [
    "len(doc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T12:29:38.402517Z",
     "start_time": "2023-02-22T12:29:38.397350Z"
    }
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rebuild a 'special' X : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T12:29:57.776240Z",
     "start_time": "2023-02-22T12:29:57.727833Z"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(doc_vectors)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T12:30:04.386526Z",
     "start_time": "2023-02-22T12:30:04.381030Z"
    }
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    RandomForestClassifier(), {}, cv=cv(), n_jobs=-1, return_train_score=True, verbose=1,\n",
    ")\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "display(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultize : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultize(grid, head=20):\n",
    "\n",
    "    res = pd.DataFrame(grid.cv_results_)\n",
    "    cols = [i for i in res.columns if \"split\" not in i]\n",
    "    res = res.loc[:, cols]\n",
    "    res = res.round(2).sort_values(\"mean_test_score\", ascending=False).head(head)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "resultize(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", \"passthrough\"),\n",
    "        (\"scaler\", \"passthrough\"),\n",
    "        (\"reductor\", \"passthrough\"),\n",
    "        (\"estimator\", LogisticRegression()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is \"passthrough\" : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = \"passthrough\"\n",
    "\n",
    "pst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Param grid : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"scaler\": [\n",
    "        \"passthrough\",\n",
    "        StandardScaler(),\n",
    "        QuantileTransformer(n_quantiles=100),\n",
    "        # MinMaxScaler(),\n",
    "        Normalizer(),\n",
    "    ],\n",
    "    \"reductor\": [PCA()],\n",
    "    \"reductor__n_components\": [0.7, 0.85, 0.9, 0.95, 0.99],\n",
    "    \"estimator\": [RandomForestClassifier(), LogisticRegression()],\n",
    "}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New grid : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv(),\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultize(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a custom transformer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Transformer : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Doc2VecTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, model=None, vector_size=500, window=5, min_count=5, epochs=100):\n",
    "\n",
    "        self.vector_size = vector_size\n",
    "        self.window = window\n",
    "        self.min_count = min_count\n",
    "        self.epochs = epochs\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        if not isinstance(X, list):\n",
    "            _X = X.values.tolist()\n",
    "        else:\n",
    "            _X = X\n",
    "\n",
    "        if self.model : \n",
    "            return self\n",
    "\n",
    "        tagged_docs = [\n",
    "            TaggedDocument(words=preprocess_string(doc), tags=[i])\n",
    "            for i, doc in enumerate(_X)\n",
    "        ]\n",
    "        model = Doc2Vec(\n",
    "            vector_size=self.vector_size, min_count=self.min_count, epochs=self.epochs\n",
    "        )\n",
    "        model.build_vocab(tagged_docs)\n",
    "        model.train(tagged_docs, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "        self.model = model\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        if not isinstance(X, list):\n",
    "            _X = X.values.tolist()\n",
    "        else:\n",
    "            _X = X\n",
    "\n",
    "        vectors = [self.model.infer_vector(preprocess_string(i)) for i in X]\n",
    "        return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original df : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init d2f : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v = Doc2VecTransformer()\n",
    "d2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v.fit(df.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"my new watch is a very funny flic flac digital chronometer\"]\n",
    "d2v.transform(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With pretrained model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v = Doc2VecTransformer(model=model_xl)\n",
    "text = [\"my new watch is a very funny flic flac digital chronometer\"]\n",
    "d2v.transform(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New param grid : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"preprocessor\": [Doc2VecTransformer()]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Grid : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    pipeline, param_grid, cv=cv(), n_jobs=-1, return_train_score=True, verbose=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(df.description, y)\n",
    "\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(grid.best_estimator_)\n",
    "resultize(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing various transformers params : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"preprocessor\": [Doc2VecTransformer()],\n",
    "    \"preprocessor__vector_size\": [100, 200, 500],\n",
    "    \"preprocessor__window\": [5, 10, 15],\n",
    "    # preprocessor__model = [model_sm, model_md, model_lg, model_xl]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    pipeline, param_grid, cv=cv(), n_jobs=-1, return_train_score=True, verbose=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(df.description, y)\n",
    "\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = resultize(grid, head=30)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our problem is : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "px.scatter_3d(res, x=\"param_preprocessor__vector_size\", y=\"mean_test_score\", z=\"param_preprocessor__window\",)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With box plots : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(\n",
    "    res,\n",
    "    x=\"param_preprocessor__vector_size\",\n",
    "    y=\"mean_test_score\",\n",
    "    # color=\"param_preprocessor__window\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    res.loc[res.param_preprocessor__window == 15],\n",
    "    x=\"mean_score_time\",\n",
    "    y=\"mean_test_score\",\n",
    "    # color=\"param_preprocessor__window\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenAI GPT Emedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init your client : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = df.description.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a try : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.embeddings.create(\n",
    "    input=doc, model=\"text-embedding-3-small\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is response : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vector : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = response.data[0].embedding\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of Vectors ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# li = []\n",
    "\n",
    "# for i in df.description.values :\n",
    "#     # print(i)\n",
    "\n",
    "#     response = client.embeddings.create(\n",
    "#     input=i, model=\"text-embedding-3-small\",)\n",
    "#     vector = response.data[0].embedding\n",
    "#     li.append(vector)\n",
    "\n",
    "# li = pd.DataFrame(li)\n",
    "# li.to_csv(\"df_from_gpt.csv\", index=False)\n",
    "# li\n",
    "\n",
    "li = pd.read_csv(\"df_from_gpt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a custom transformer : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenAIVecTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, model=\"text-embedding-3-small\"):\n",
    "\n",
    "        self.model = model\n",
    "        self.client = OpenAI()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        if not isinstance(X, list):\n",
    "            _X = X.values.tolist()\n",
    "        else:\n",
    "            _X = X\n",
    "\n",
    "        get_vect = lambda  i : self.client.embeddings.create(input=i, model=self.model).data[0].embedding\n",
    "        X_ = [get_vect(i) for i in X]\n",
    "\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a very basic Pipeline / grid search : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        # (\"preprocessor\", \"passthrough\"),\n",
    "        (\"scaler\", \"passthrough\"),\n",
    "        # (\"reductor\", \"passthrough\"),\n",
    "        (\"estimator\", RandomForestClassifier()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is \"passthrough\" : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = \"passthrough\"\n",
    "\n",
    "pst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Param grid : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"scaler\": [\n",
    "        \"passthrough\",\n",
    "        StandardScaler(),\n",
    "        QuantileTransformer(n_quantiles=100),\n",
    "        # MinMaxScaler(),\n",
    "        Normalizer(),\n",
    "    ],\n",
    "    # \"reductor\": [PCA()],\n",
    "    # \"reductor__n_components\": [0.7, 0.85, 0.9, 0.95, 0.99],\n",
    "    \"estimator\": [\n",
    "        RandomForestClassifier(),\n",
    "    ],  # LogisticRegression()\n",
    "}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New grid : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv(),\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "grid.fit(li, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultize(grid)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "NENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd158c7f1a670d1d188328ca41323458089a3c8a74c42040854dc6ec477fbf56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
