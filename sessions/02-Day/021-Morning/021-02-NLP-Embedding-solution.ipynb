{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 021-02 - NLP Embedding - Solution Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Written by Alexandre Gazagnes\n",
    "* Last update: 2024-02-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the party started ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data  : \n",
    "\n",
    "**You can find the dataset [here](https://gist.githubusercontent.com/AlexandreGazagnes/cabe445634a092d308d17a883a305a75/raw/9f785f0f02739ac6352e1d583323771d55270221/nlp.csv).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These commands will display the system information:\n",
    "\n",
    "Uncomment theses lines if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install various Librairies : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt >> pip.log\n",
    "# !pip freeze >> pip.freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, warnings, secrets, datetime\n",
    "import pickle\n",
    "from IPython.display import display\n",
    "\n",
    "# from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.impute import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.pipeline import *\n",
    "from sklearn.feature_extraction import *\n",
    "from sklearn.dummy import *\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "# from lightgbm import *\n",
    "# from xgboost import *\n",
    "\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.neighbors import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "\n",
    "# import wordcloud\n",
    "\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.corpus import words\n",
    "# from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "# import string\n",
    "\n",
    "import spacy\n",
    "\n",
    "# from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.downloader import load\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.parsing.preprocessing import preprocess_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  # HTTP client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "# warnings.filterwarnings(action=\"once\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If needed we can use a TEST_MODE to run the notebook to have a very fast execution : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_MODE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = 10  # number of folds for the  cross val\n",
    "N_JOBS = 7  # number of cpu to use for computations\n",
    "FRAC = 1.0  # we keep 100% of the dataframe\n",
    "DISPLAY = True  # display complex viz\n",
    "TEST_SIZE = 0.25  # Train vs Test %\n",
    "\n",
    "if TEST_MODE:\n",
    "    CV = 3\n",
    "    N_JOBS = -1\n",
    "    FRAC = 0.3\n",
    "    DISPLAY = False\n",
    "    TEST_SIZE = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thrid Parties Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need some Third parties : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download(\"punkt\")\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some string assets : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = set(stopwords.words(\"english\"))\n",
    "# punctuation = set(string.punctuation)\n",
    "# word_dict = words.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to download spacy : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download en_core_web_md\n",
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2vect : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2c = load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to load spacy model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have an error please run the download command for spacy : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "url of the dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://gist.githubusercontent.com/AlexandreGazagnes/cabe445634a092d308d17a883a305a75/raw/d2014e8a34bba3c1be3ec8936bb338fb42888f24/nlp.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(url)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep a copy of the df : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_MODE:\n",
    "    df = df.sample(frac=FRAC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## King - Men + Woman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize 'King' : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "king = nlp(\"king\")\n",
    "king"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(king)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the vector : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "king_v = king.vector\n",
    "king_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(king.vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for Man : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "man = nlp(\"man\")\n",
    "man_v = man.vector\n",
    "man_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(man_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for wooman : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woman = nlp(\"woman\")\n",
    "woman_v = woman.vector\n",
    "woman_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fancy calculation ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = king_v - man_v + woman_v\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape new vector : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.reshape(1, -1)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Similarity : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = nlp.vocab.vectors.most_similar(res, n=20)\n",
    "vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v1 is : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = vectors[0][0][0]\n",
    "v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vect is :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = nlp.vocab[v1]\n",
    "vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text is :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = vectors[0][0][1]\n",
    "vect = nlp.vocab[v2]\n",
    "vect.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3 = vectors[0][0][2]\n",
    "vect = nlp.vocab[v3]\n",
    "vect.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoooo .... not so good ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do the same with a \"huge\" model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download en_core_web_md\n",
    "!python -m spacy download en_core_web_lg\n",
    "# !python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good ? ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just re-run previous cells with this code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are your conclusions ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try another last trick : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"He is one of the most famous kings:  Richard III was the last king of England to die in battle\"\n",
    "doc = nlp(doc)\n",
    "king = doc[-7]\n",
    "king"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "king_v = king.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"Fifteen months after the death of King George VI, his daughter Elizabeth is crowned Queen of England\"\n",
    "doc = nlp(doc)\n",
    "queen = doc[-3]\n",
    "queen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queen_v = queen.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"a female, it's a woman, or a lady, a human of female sex.\"\n",
    "doc = nlp(doc)\n",
    "woman = doc[6]\n",
    "woman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woman_v = woman.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "king_v = king.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"a boy, a guy, or a man, it's a human being of male sex.\"\n",
    "doc = nlp(doc)\n",
    "man = doc[8]\n",
    "man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "man_v = man.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = nlp.vocab.vectors.most_similar(queen_v.reshape(1, -1), n=20)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t_id in out[0][0]:\n",
    "    print(nlp.vocab[t_id].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Doc2Vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same with Pretrained Doct2Vect : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = w2c.most_similar(positive=[\"woman\", \"king\"], negative=[\"man\"], topn=10)\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create y vector : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T12:18:27.463765Z",
     "start_time": "2023-02-22T12:18:27.277572Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df.cat_1\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create X : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.description\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv():\n",
    "    return StratifiedShuffleSplit(n_splits=CV, test_size=TEST_SIZE)\n",
    "\n",
    "\n",
    "cv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our documents : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T12:24:50.897459Z",
     "start_time": "2023-02-22T12:24:50.890472Z"
    }
   },
   "outputs": [],
   "source": [
    "documents = df.description\n",
    "documents[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init spacy : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have an error please download en_core_web_lg model for spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess (clean) the corpus : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T12:25:42.803825Z",
     "start_time": "2023-02-22T12:25:22.555754Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_docs = [\n",
    "    [\n",
    "        token.lemma_\n",
    "        for token in nlp(doc.lower())\n",
    "        if not token.is_stop and not token.is_punct\n",
    "    ]\n",
    "    for doc in documents\n",
    "]\n",
    "tokenized_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key concept here is a tagged document => Token + id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_docs = [\n",
    "    TaggedDocument(words=doc, tags=[i]) for i, doc in enumerate(tokenized_docs)\n",
    "]\n",
    "tagged_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Doc2Vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Gensim Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sm : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T12:26:12.958857Z",
     "start_time": "2023-02-22T12:26:04.105331Z"
    }
   },
   "outputs": [],
   "source": [
    "# 5s\n",
    "model_sm = Doc2Vec(\n",
    "    tagged_docs,\n",
    "    vector_size=50,  # size of output vect\n",
    "    window=2,  # nb words before and after a target word\n",
    "    min_count=1,  # minimum frequency count of words. ,\n",
    "    workers=4,  # number of cpu\n",
    "    epochs=100,  # number of iterations (passes over the entire dataset)\n",
    ")\n",
    "\n",
    "model_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "md : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10s\n",
    "model_md = Doc2Vec(\n",
    "    tagged_docs,\n",
    "    vector_size=100,\n",
    "    window=4,\n",
    "    min_count=1,\n",
    "    workers=4,\n",
    "    epochs=200,\n",
    ")\n",
    "model_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lg : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30s\n",
    "model_lg = Doc2Vec(\n",
    "    tagged_docs,\n",
    "    vector_size=500,\n",
    "    window=10,\n",
    "    min_count=1,\n",
    "    workers=4,\n",
    "    epochs=500,\n",
    ")\n",
    "model_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xl : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 15m => 1h\n",
    "# model_xxl = Doc2Vec(\n",
    "#     tagged_docs,\n",
    "#     vector_size=1_000,\n",
    "#     window=10,\n",
    "#     min_count=3,\n",
    "#     workers=6,\n",
    "#     epochs=2_000,\n",
    "# )\n",
    "# model_xxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1m => 3m\n",
    "model_xl = Doc2Vec(\n",
    "    tagged_docs,\n",
    "    vector_size=1_000,\n",
    "    window=10,\n",
    "    min_count=1,\n",
    "    workers=4,\n",
    "    epochs=1_000,\n",
    ")\n",
    "model_xl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the vectors : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T12:29:24.481191Z",
     "start_time": "2023-02-22T12:29:13.060124Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2 => 5 mins with xl\n",
    "\n",
    "doc_vectors = []\n",
    "for doc in tokenized_docs:\n",
    "    vector = model_xl.infer_vector(doc)\n",
    "    doc_vectors.append(vector)\n",
    "\n",
    "doc_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more pythonic implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectors = [model_xl.infer_vector(doc) for doc in tokenized_docs]\n",
    "doc_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Type : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T12:29:24.491186Z",
     "start_time": "2023-02-22T12:29:24.486319Z"
    }
   },
   "outputs": [],
   "source": [
    "type(doc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(doc_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length ? : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T12:29:33.460373Z",
     "start_time": "2023-02-22T12:29:33.456054Z"
    }
   },
   "outputs": [],
   "source": [
    "len(doc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T12:29:38.402517Z",
     "start_time": "2023-02-22T12:29:38.397350Z"
    }
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rebuild a 'special' X : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T12:29:57.776240Z",
     "start_time": "2023-02-22T12:29:57.727833Z"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(doc_vectors)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(\"df_from_doc2vect_model_xl.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T12:30:04.386526Z",
     "start_time": "2023-02-22T12:30:04.381030Z"
    }
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    RandomForestClassifier(),\n",
    "    {},\n",
    "    cv=CV,\n",
    "    n_jobs=N_JOBS,\n",
    "    return_train_score=True,\n",
    "    verbose=1,\n",
    ")\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultize : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultize(grid, head=20, export=False, token=None):\n",
    "\n",
    "    res = grid.cv_results_\n",
    "    res = pd.DataFrame(res)\n",
    "\n",
    "    cols = [i for i in res.columns if \"split\" not in i]\n",
    "    res = res.loc[:, cols]\n",
    "\n",
    "    res = res.drop(columns=[\"mean_score_time\", \"std_score_time\"])\n",
    "\n",
    "    res = res.round(2).sort_values(\"mean_test_score\", ascending=False)\n",
    "\n",
    "    if export:\n",
    "        _res = res.copy().head(head)\n",
    "        _res[\"token\"] = token\n",
    "        _res = _res.astype(str)\n",
    "        now = str(datetime.datetime.now())[:19].replace(\" \", \"_\")\n",
    "        _res.to_csv(f\"results__{token}__{now}.csv\", index=False)\n",
    "\n",
    "    return res.head(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultize(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", \"passthrough\"),\n",
    "        (\"scaler\", \"passthrough\"),\n",
    "        (\"reductor\", \"passthrough\"),\n",
    "        (\"estimator\", LogisticRegression()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is \"passthrough\" : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = \"passthrough\"\n",
    "\n",
    "pst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Param grid : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"scaler\": [\n",
    "        \"passthrough\",\n",
    "        StandardScaler(),\n",
    "        QuantileTransformer(n_quantiles=100),\n",
    "        Normalizer(),\n",
    "    ],\n",
    "    \"reductor\": [PCA()],\n",
    "    \"reductor__n_components\": [0.7, 0.85, 0.9, 0.95, 0.99],\n",
    "    \"estimator\": [RandomForestClassifier(), LogisticRegression()],\n",
    "}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New grid : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=CV,\n",
    "    n_jobs=N_JOBS,\n",
    "    return_train_score=True,\n",
    "    verbose=1,\n",
    ")\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultize(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a custom transformer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Transformer : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Doc2VecTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model=None,\n",
    "        vector_size=500,\n",
    "        window=5,\n",
    "        min_count=5,\n",
    "        epochs=100,\n",
    "    ):\n",
    "\n",
    "        self.vector_size = vector_size\n",
    "        self.window = window\n",
    "        self.min_count = min_count\n",
    "        self.epochs = epochs\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        if not isinstance(X, list):\n",
    "            _X = X.values.tolist()\n",
    "        else:\n",
    "            _X = X\n",
    "\n",
    "        if self.model:\n",
    "            return self\n",
    "\n",
    "        tagged_docs = [\n",
    "            TaggedDocument(words=preprocess_string(doc), tags=[i])\n",
    "            for i, doc in enumerate(_X)\n",
    "        ]\n",
    "        model = Doc2Vec(\n",
    "            vector_size=self.vector_size, min_count=self.min_count, epochs=self.epochs\n",
    "        )\n",
    "        model.build_vocab(tagged_docs)\n",
    "        model.train(tagged_docs, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "        self.model = model\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        if not isinstance(X, list):\n",
    "            _X = X.values.tolist()\n",
    "        else:\n",
    "            _X = X\n",
    "\n",
    "        vectors = [self.model.infer_vector(preprocess_string(i)) for i in X]\n",
    "        return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original df : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init d2f : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v = Doc2VecTransformer()\n",
    "d2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v.fit(df.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"my new watch is a very funny flic flac digital chronometer\"]\n",
    "vector_list = d2v.transform(text)\n",
    "vector_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be sure : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With pretrained model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"my new watch is a very funny flic flac digital chronometer\"]\n",
    "d2v = Doc2VecTransformer(model=model_xl)\n",
    "d2v.transform(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New param grid : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"preprocessor\": [Doc2VecTransformer()]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Grid : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=CV,\n",
    "    n_jobs=N_JOBS,\n",
    "    return_train_score=True,\n",
    "    verbose=2,\n",
    ")\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(df.description.values, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultize(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as a remainder : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 30s\n",
    "# model_lg = Doc2Vec(\n",
    "#     tagged_docs,\n",
    "#     vector_size=500,\n",
    "#     window=10,\n",
    "#     min_count=1,\n",
    "#     workers=4,\n",
    "#     epochs=500,\n",
    "# )\n",
    "# model_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing various transformers params : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"preprocessor\": [Doc2VecTransformer()],\n",
    "    \"preprocessor__vector_size\": [500],  # 100, 200, # 1000\n",
    "    \"preprocessor__window\": [5],  # 5, 10, 5, 10,   # 20, 25, 30\n",
    "    \"preprocessor__epochs\": [500],\n",
    "    \"preprocessor__min_count\": [1, 3],  # 100, 300,  # 1000\n",
    "    \"estimator\": [LogisticRegression(), RandomForestClassifier()],\n",
    "    # preprocessor__model = [model_sm, model_md, model_lg, model_xl]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     \"preprocessor\": [Doc2VecTransformer()],\n",
    "#     \"preprocessor__vector_size\": [500, 1000],  # 100, 200, # 1000\n",
    "#     \"preprocessor__window\": [5, 10, 15],  # 5, 10, 5, 10,   # 20, 25, 30\n",
    "#     \"preprocessor__epochs\": [500, 1000],\n",
    "#     \"preprocessor__min_count\": [1, 3, 5],  # 100, 300,  # 1000\n",
    "#     # preprocessor__model = [model_sm, model_md, model_lg, model_xl]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     \"preprocessor\": [Doc2VecTransformer()],\n",
    "#     \"preprocessor__vector_size\": [500],  # 100, 200, # 1000\n",
    "#     \"preprocessor__window\": [5, 10],  # 5, 10, 5, 10,   # 20, 25, 30\n",
    "#     \"preprocessor__epochs\": [500],\n",
    "#     \"preprocessor__min_count\": [1, 3, 5],  # 100, 300,  # 1000\n",
    "#     # preprocessor__model = [model_sm, model_md, model_lg, model_xl]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     \"preprocessor\": [Doc2VecTransformer()],\n",
    "#     \"preprocessor__vector_size\": [500, 1000],  # 100, 200, # 1000\n",
    "#     \"preprocessor__window\": [10, 15],  # 5, 10, 5, 10,   # 20, 25, 30\n",
    "#     \"preprocessor__epochs\": [500, 1000],\n",
    "#     \"preprocessor__min_count\": [1, 3, 5],  # 100, 300,  # 1000\n",
    "#     # preprocessor__model = [model_sm, model_md, model_lg, model_xl]\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=CV,\n",
    "    n_jobs=N_JOBS,\n",
    "    return_train_score=True,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(df.description, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = resultize(grid, head=30)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post mortem analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our problem is : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_3d(\n",
    "    res,\n",
    "    x=\"param_preprocessor__vector_size\",\n",
    "    y=\"mean_test_score\",\n",
    "    z=\"param_preprocessor__window\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With box plots : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(\n",
    "    res,\n",
    "    x=\"param_preprocessor__vector_size\",\n",
    "    y=\"mean_test_score\",\n",
    "    # color=\"param_preprocessor__window\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    res.loc[res.param_preprocessor__window == 15],\n",
    "    x=\"mean_score_time\",\n",
    "    y=\"mean_test_score\",\n",
    "    # color=\"param_preprocessor__window\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline = grid.best_estimator_\n",
    "best_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unique id for our model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = secrets.token_hex(4)\n",
    "token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = str(datetime.datetime.now())[:19].replace(\" \", \"_\")\n",
    "now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filename : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = f\"gensim_model__{token}__{now}.pk\"\n",
    "fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving with pickle : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fn, \"wb\") as f:\n",
    "    pickle.dump(best_pipeline, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of our model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(best_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a function : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(model, base_fn, token=None, score=None):\n",
    "    \"\"\"Saving our model\"\"\"\n",
    "\n",
    "    if not token:\n",
    "        token = secrets.token_hex(4)\n",
    "\n",
    "    now = str(datetime.datetime.now())[:19].replace(\" \", \"_\")\n",
    "\n",
    "    fn = f\"{base_fn}__{token}__{now}\"\n",
    "    if score:\n",
    "        fn += \"__\" + str(round(score, 2))\n",
    "\n",
    "    with open(fn + \".pk\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    return fn, sys.getsizeof(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save our model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = save(best_pipeline, \"gensim_model\")\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save our Transformer : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = save(Doc2VecTransformer, \"d2v_trasnformer\")\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to be sure  : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline.predict([\"i have a beautiful analogic watch rolex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.predict([\"i have a beautiful analogic watch rolex\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(fn):\n",
    "\n",
    "    if not os.path.isfile(fn):\n",
    "        raise AttributeError(f\"The File {fn} do not exists!\")\n",
    "\n",
    "    with open(fn, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    return model, sys.getsizeof(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of .pk files :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_list = os.listdir()\n",
    "fn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in fn_list if \".pk\" in i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"-- THE FILE NAME OF YOUR MODEL --\"\n",
    "\n",
    "loaded_pipeline, _ = load(fn)\n",
    "loaded_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing our loaded model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_pipeline.predict([\"i have a beautiful analogic watch rolex\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using OpenAI GPT Emedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init your client : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = df.description.iloc[0]\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a try : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.embeddings.create(\n",
    "    input=doc,\n",
    "    model=\"text-embedding-3-small\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is response : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vector : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = response.data[0].embedding\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of Vectors ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# li = []\n",
    "\n",
    "# for doc in df.description.values :\n",
    "#     # print(i)\n",
    "\n",
    "#     response = client.embeddings.create(\n",
    "#         input=doc,\n",
    "#         model=\"text-embedding-3-small\",\n",
    "#     )\n",
    "#     vector = response.data[0].embedding\n",
    "#     li.append(vector)\n",
    "\n",
    "# li = pd.DataFrame(li)\n",
    "# li.to_csv(\"df_from_gpt.csv\", index=False)\n",
    "# li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or load this file : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = pd.read_csv(\"df_from_gpt.csv\")\n",
    "li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a custom transformer : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenAIVecTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, model=\"text-embedding-3-small\"):\n",
    "\n",
    "        self.model = model\n",
    "        self.client = OpenAI()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        if not isinstance(X, list):\n",
    "            _X = X.values.tolist()\n",
    "        else:\n",
    "            _X = X\n",
    "\n",
    "        get_vect = (\n",
    "            lambda i: self.client.embeddings.create(\n",
    "                input=i,\n",
    "                model=self.model,\n",
    "            )\n",
    "            .data[0]\n",
    "            .embedding\n",
    "        )\n",
    "        X_ = [get_vect(i) for i in X]\n",
    "\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a very basic Pipeline / grid search : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", \"passthrough\"),\n",
    "        (\"scaler\", \"passthrough\"),\n",
    "        (\"reductor\", \"passthrough\"),\n",
    "        (\"estimator\", RandomForestClassifier()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is \"passthrough\" : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = \"passthrough\"\n",
    "pst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Param grid : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"scaler\": [\n",
    "        \"passthrough\",\n",
    "        StandardScaler(),\n",
    "        QuantileTransformer(n_quantiles=100),\n",
    "        Normalizer(),\n",
    "    ],\n",
    "    # \"reductor\": [PCA()],\n",
    "    # \"reductor__n_components\": [0.7, 0.85, 0.9, 0.95, 0.99],\n",
    "    \"estimator\": [RandomForestClassifier()],  # LogisticRegression()\n",
    "}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New grid : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=CV,\n",
    "    n_jobs=N_JOBS,\n",
    "    return_train_score=True,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "grid.fit(li, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultize(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using our own API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://centrale-casa-api.onrender.com\"\n",
    "\n",
    "\n",
    "route = \"/predict/\"\n",
    "\n",
    "data = \"watches\"\n",
    "response = requests.get(url + route + data)\n",
    "\n",
    "response.json()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd158c7f1a670d1d188328ca41323458089a3c8a74c42040854dc6ec477fbf56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
