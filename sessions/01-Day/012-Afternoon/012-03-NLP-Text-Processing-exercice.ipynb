{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 012-03 - NLP Text Processing - Exercice Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Written by Alexandre Gazagnes\n",
    "* Last update: 2024-02-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are gonna implement our 1st NLP tool ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data  : \n",
    "\n",
    "**You can find the dataset [here](https://gist.githubusercontent.com/AlexandreGazagnes/cabe445634a092d308d17a883a305a75/raw/9f785f0f02739ac6352e1d583323771d55270221/nlp.csv).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "PBabb1xmqSlM"
   },
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "dAhj129JqdaC"
   },
   "source": [
    "### System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These commands will display the system information:\n",
    "\n",
    "Uncomment theses lines if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "yE-usmhkycvz"
   },
   "source": [
    "Install various Librairies : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T06:58:57.038920Z",
     "start_time": "2023-02-23T06:58:57.032717Z"
    },
    "hidden": true,
    "id": "sfsFooZVqajD"
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt >> pip.log\n",
    "# !pip freeze >> pip.freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "xVpywqWAqalg"
   },
   "source": [
    "### Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T06:58:59.595289Z",
     "start_time": "2023-02-23T06:58:57.672688Z"
    },
    "hidden": true,
    "id": "Rt4va8LsqnGR"
   },
   "outputs": [],
   "source": [
    "import os, sys, warnings\n",
    "import pickle\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.impute import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.pipeline import *\n",
    "from sklearn.feature_extraction import *\n",
    "from sklearn.dummy import *\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "# from lightgbm import *\n",
    "# from xgboost import *\n",
    "\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.neighbors import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import wordcloud\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "import string\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "xkZ4K9CRqaoM"
   },
   "source": [
    "### Graphs and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T06:58:59.600629Z",
     "start_time": "2023-02-23T06:58:59.597369Z"
    },
    "hidden": true,
    "id": "34QZa76rqxLu"
   },
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T06:58:59.604999Z",
     "start_time": "2023-02-23T06:58:59.602475Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action=\"once\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T06:58:59.610007Z",
     "start_time": "2023-02-23T06:58:59.607152Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DISPLAY = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Thrid Parties Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need some Third parties : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T06:59:00.115507Z",
     "start_time": "2023-02-23T06:59:00.044665Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# nltk  download punkt stopwords words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some string assets : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T06:59:00.491350Z",
     "start_time": "2023-02-23T06:59:00.420416Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# stop_words \n",
    "# punctuation \n",
    "# word_dict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to download spacy : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T06:59:01.023888Z",
     "start_time": "2023-02-23T06:59:01.016385Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# download scapcy sm and md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to load spacy model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T06:59:01.130801Z",
     "start_time": "2023-02-23T06:59:01.128456Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "FUVeEfm9qx8f"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "url of the dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T06:59:01.819218Z",
     "start_time": "2023-02-23T06:59:01.811890Z"
    },
    "hidden": true,
    "id": "o_SlDzD1r4KP"
   },
   "outputs": [],
   "source": [
    "url = \"https://gist.githubusercontent.com/AlexandreGazagnes/cabe445634a092d308d17a883a305a75/raw/d2014e8a34bba3c1be3ec8936bb338fb42888f24/nlp.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T06:59:02.206962Z",
     "start_time": "2023-02-23T06:59:02.172398Z"
    },
    "hidden": true,
    "id": "4LfAEaWRrzTz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep a copy of the df : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T14:50:27.970009Z",
     "start_time": "2023-02-10T14:50:27.432446Z"
    },
    "heading_collapsed": true,
    "id": "kzoLQvf44HRX"
   },
   "source": [
    "## First tour "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample 10 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T06:59:04.207912Z",
     "start_time": "2023-02-23T06:59:04.190392Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Info : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value counts : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specific data types : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# nunique on object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Nan & Dupliacted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any missing values : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# axis 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# axis 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any duplicated : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Data Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some numerical stats : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other stats :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select numeric : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select non numeric : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Text Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Display All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[print(i + \"\\n\\n\") for i in df.description.head().values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sample "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Display by cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "\n",
    "key = df.cat_1.unique()[i]\n",
    "\n",
    "print(\"--------------------------------------------\")\n",
    "print(f\"-------------- {key} --------------- \")\n",
    "print(\"--------------------------------------------\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "for k in df.cat_1.unique()[0]:\n",
    "    tmp = df.loc[df.cat_1 == k, :]\n",
    "    [print(i[:lim] + \"\\n\\n\") for i in df.description.head(5).values]\n",
    "    [print(i[:lim] + \"\\n\\n\") for i in df.description.sample(5).values]\n",
    "    [print(i[:lim] + \"\\n\\n\") for i in df.description.tail(5).values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def print_categ(i) : \n",
    "\n",
    "    # some code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print Categ 1 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print Categ 2 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Text To Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize with NLTK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create doc from 1st description : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descr 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize with nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Stop words : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our punctuation : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "English dictionnary (lower) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word_dict[10000:10010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets build a function : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_tokenizer(\n",
    "    doc: str,\n",
    "    len_min_word: int = 3,\n",
    "    force_lower: bool = True,\n",
    "    remove_stop_words=True,\n",
    "    remove_punct=True,\n",
    "    remove_all_digit=True,\n",
    "    remove_any_digit=False,\n",
    "    list_dict_word=None,\n",
    "    list_extra_stop_word=None,\n",
    "    remove_duplicate=False,\n",
    ") -> str:\n",
    "\n",
    "    if force_lower:\n",
    "        doc = doc.lower()  # if force_lower else doc\n",
    "\n",
    "    doc = doc.strip()\n",
    "\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "\n",
    "    if remove_stop_words:\n",
    "        tokens = [t for t in tokens if t not in stop_words]\n",
    "\n",
    "    if remove_punct:\n",
    "        tokens = [t for t in tokens if t not in punctuation]\n",
    "\n",
    "    if len_min_word > 0:\n",
    "        tokens = [t for t in tokens if len(t) >= len_min_word]\n",
    "\n",
    "    if remove_all_digit:\n",
    "        tokens = [t for t in tokens if not t.isdigit()]\n",
    "\n",
    "    if remove_any_digit:\n",
    "\n",
    "        def has_a_digit(i):\n",
    "            for char in i:\n",
    "                if char.isdigit():\n",
    "                    return True\n",
    "            return False\n",
    "\n",
    "        tokens = [\n",
    "            t for t in tokens if not has_a_digit(i)\n",
    "        ]  # any(map(str.isdigit, list(t)))]\n",
    "\n",
    "    if list_dict_word:\n",
    "        tokens = [t for t in tokens if t in list_dict_word]\n",
    "\n",
    "    if list_extra_stop_word:\n",
    "        tokens = [t for t in tokens if t not in list_extra_stop_word]\n",
    "\n",
    "    if remove_duplicate:\n",
    "        tokens = list(set(tokens))\n",
    "\n",
    "    return \" \".join(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize With Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same with spacy : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"I'm so happy to live here, because this will be the most beautiful place on earth!!!\"\n",
    "# tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop words : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"I'm so happy to live here because this will be the most beautiful place on earth\"\n",
    "# is_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Punctuation : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"I'm so happy to live here because this will be the most beautiful place on earth\"\n",
    "# is_punct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is Digit : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"I'm so happy to live here because this will be the most beautiful place on earth\"\n",
    "# isdigit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of speech  : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"I'm so happy to live here because this will be the most beautiful place on earth\"\n",
    "\n",
    "pos_list = [\"NOUN\", \"VERB\", \"ADJ\", \"ADV\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmentization : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"I'm so happy to live here because this will be the most beautiful place on earth\"\n",
    "# lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenizer(\n",
    "    doc,\n",
    "    len_min_word=3,\n",
    "    force_lower=True,\n",
    "    remove_stop_words=True,\n",
    "    remove_punct=True,\n",
    "    remove_digit_token=True,\n",
    "    remove_all_digit=True,\n",
    "    pos_list=[\"NOUN\", \"VERB\", \"ADJ\", \"ADV\"],\n",
    "    lemmentize=True,\n",
    "    list_dict_word=None,\n",
    "    list_extra_stop_word=None,\n",
    "):\n",
    "    doc = doc.lower() if force_lower else doc\n",
    "\n",
    "    doc = doc.strip()\n",
    "\n",
    "    tokens = nlp(doc)\n",
    "\n",
    "    if remove_stop_words:\n",
    "        tokens = [t for t in tokens if not t.is_stop]\n",
    "\n",
    "    if remove_punct:\n",
    "        tokens = [t for t in tokens if not t.is_punct]\n",
    "\n",
    "    tokens = [t for t in tokens if len(t) >= len_min_word]\n",
    "\n",
    "    if remove_digit_token:\n",
    "        tokens = [t for t in tokens if not t.text.isdigit()]\n",
    "\n",
    "    if remove_all_digit:\n",
    "        tokens = [t for t in tokens if not any(map(str.isdigit, list(t.text)))]\n",
    "\n",
    "    if pos_list:\n",
    "        tokens = [t for t in tokens if t.pos_ in pos_list]\n",
    "\n",
    "    if lemmentize:\n",
    "        tokens = [t.lemma_ for t in tokens]\n",
    "\n",
    "    if list_dict_word:\n",
    "        tokens = [t for t in tokens if t.text in list_dict_word]\n",
    "\n",
    "    if list_extra_stop_word:\n",
    "        tokens = [t for t in tokens if t.text not in list_extra_stop_word]\n",
    "\n",
    "    return \" \".join(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = df.description.iloc[0]\n",
    "res = spacy_tokenizer(doc)\n",
    "print(res)\n",
    "print(len(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer and TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create an artificial corpus : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"my cat is red\",\n",
    "    \"my cat is blue\",\n",
    "    \"my cat is yellow, i know that is wierd but he is yellow, yellow, yellow\",\n",
    "]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a pd.Series : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.Series(corpus, name=\"text\")\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init a Count Vectorizer : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usefull dataframe : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same with TFIDF : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T06:59:18.319086Z",
     "start_time": "2023-02-23T06:59:18.226388Z"
    }
   },
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T06:59:18.981572Z",
     "start_time": "2023-02-23T06:59:18.933709Z"
    }
   },
   "outputs": [],
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T06:59:19.379883Z",
     "start_time": "2023-02-23T06:59:19.373821Z"
    }
   },
   "outputs": [],
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T06:59:19.756247Z",
     "start_time": "2023-02-23T06:59:19.748349Z"
    }
   },
   "outputs": [],
   "source": [
    "def cv():\n",
    "    return StratifiedShuffleSplit(n_splits=10, test_size=0.25)\n",
    "\n",
    "\n",
    "cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T06:59:59.289390Z",
     "start_time": "2023-02-23T06:59:59.140674Z"
    }
   },
   "outputs": [],
   "source": [
    "# grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T07:00:02.474316Z",
     "start_time": "2023-02-23T07:00:02.457408Z"
    }
   },
   "outputs": [],
   "source": [
    "def resultize(grid) : \n",
    "\n",
    "    res = pd.DataFrame(grid.cv_results_)\n",
    "    cols = [i for i in res.columns if \"split\" not in i]\n",
    "    res = res.loc[:, cols]\n",
    "    res = res.round(2).sort_values(\"mean_test_score\", ascending=False).head(10)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Basic Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"estimator\": [\n",
    "        LogisticRegression(),\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Reductor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Advanced Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NltkTokenizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        len_min_word=3,\n",
    "        force_lower=True,\n",
    "        remove_stop_words=True,\n",
    "        remove_punct=True,\n",
    "        remove_digit_token=True,\n",
    "        remove_all_digit=True,\n",
    "        list_dict_word=None,\n",
    "        list_extra_stop_word=None,\n",
    "    ):\n",
    "        self.len_min_word = len_min_word\n",
    "        self.force_lower = force_lower\n",
    "        self.remove_stop_words = remove_stop_words\n",
    "        self.remove_punct = remove_punct\n",
    "        self.remove_digit_token = remove_digit_token\n",
    "        self.remove_all_digit = remove_all_digit\n",
    "        self.list_dict_word = list_dict_word\n",
    "        self.list_extra_stop_word = list_extra_stop_word\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        f = lambda i: nltk_tokenizer(\n",
    "            i,\n",
    "            len_min_word=self.len_min_word,\n",
    "            force_lower=self.force_lower,\n",
    "            remove_stop_words=self.remove_stop_words,\n",
    "            remove_punct=self.remove_punct,\n",
    "            remove_digit_token=self.remove_digit_token,\n",
    "            remove_all_digit=self.remove_all_digit,\n",
    "            list_dict_word=self.list_dict_word,\n",
    "            list_extra_stop_word=self.list_extra_stop_word,\n",
    "        )\n",
    "\n",
    "        return X.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpacyTokenizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        len_min_word=3,\n",
    "        force_lower=True,\n",
    "        remove_stop_words=True,\n",
    "        remove_punct=True,\n",
    "        remove_digit_token=True,\n",
    "        remove_all_digit=True,\n",
    "        list_dict_word=None,\n",
    "        list_extra_stop_word=None,\n",
    "    ):\n",
    "        self.len_min_word = len_min_word\n",
    "        self.force_lower = force_lower\n",
    "        self.remove_stop_words = remove_stop_words\n",
    "        self.remove_punct = remove_punct\n",
    "        self.remove_digit_token = remove_digit_token\n",
    "        self.remove_all_digit = remove_all_digit\n",
    "        self.list_dict_word = list_dict_word\n",
    "        self.list_extra_stop_word = list_extra_stop_word\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        f = lambda i: spacy_tokenizer(\n",
    "            i,\n",
    "            len_min_word=self.len_min_word,\n",
    "            force_lower=self.force_lower,\n",
    "            remove_stop_words=self.remove_stop_words,\n",
    "            remove_punct=self.remove_punct,\n",
    "            remove_digit_token=self.remove_digit_token,\n",
    "            remove_all_digit=self.remove_all_digit,\n",
    "            list_dict_word=self.list_dict_word,\n",
    "            list_extra_stop_word=self.list_extra_stop_word,\n",
    "        )\n",
    "\n",
    "        return X.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd158c7f1a670d1d188328ca41323458089a3c8a74c42040854dc6ec477fbf56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
